{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=7, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.1\n",
      "numpy 1.16.4\n",
      "pandas 0.24.2\n",
      "sklearn 0.21.2\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.95021296, shape=(), dtype=float32)\n",
      "tf.Tensor([-0.95021296 -0.917915  ], shape=(2,), dtype=float32)\n",
      "tf.Tensor(-0.95021296, shape=(), dtype=float32)\n",
      "tf.Tensor([-0.95021296 -0.917915  ], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.function and auto-graph\n",
    "def scaled_elu(z,scale=1.0,alpha=1.0):\n",
    "    #z > 0 ? scale * z: scale * alpha * tf.nn.elu(z)\n",
    "    is_positive = tf.greater_equal(z,0.0)\n",
    "    return scale * tf.where(is_positive,z,alpha * tf.nn.elu(z))\n",
    "print(scaled_elu(tf.constant(-3.)))\n",
    "print(scaled_elu(tf.constant([-3.,-2.5])))\n",
    "\n",
    "scaled_elu_tf = tf.function(scaled_elu)\n",
    "print(scaled_elu_tf(tf.constant(-3.)))\n",
    "print(scaled_elu_tf(tf.constant([-3.,-2.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(scaled_elu_tf.python_function is scaled_elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 ms ± 6.71 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "84.5 ms ± 5.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit scaled_elu(tf.random.normal([1000,1000]))\n",
    "%timeit scaled_elu_tf(tf.random.normal([1000,1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.9999981, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 计算1 + 1/2 + 1/2^2+ ...+ 1/2^n\n",
    "@tf.function\n",
    "def converge_to_2(n_iters):\n",
    "    total = tf.constant(0.)\n",
    "    increment = tf.constant(1.)\n",
    "    for _ in range(n_iters):\n",
    "        total += increment\n",
    "        increment /= 2.0\n",
    "    return total\n",
    "print(converge_to_2(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用tf中的autograph 将python 函数转化为 tf函数 展示\n",
    "def display_tf_code(func):\n",
    "    code = tf.autograph.to_code(func)\n",
    "    from IPython.display import display,Markdown\n",
    "    display(Markdown(\"'''python\\n{}\\n'''\".format(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "'''python\n",
       "def tf__scaled_elu(z, scale=None, alpha=None):\n",
       "  do_return = False\n",
       "  retval_ = ag__.UndefinedReturnValue()\n",
       "  with ag__.FunctionScope('scaled_elu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "    is_positive = ag__.converted_call(tf.greater_equal, (z, 0.0), None, fscope)\n",
       "    do_return = True\n",
       "    retval_ = fscope.mark_return_value(scale * ag__.converted_call(tf.where, (is_positive, z, alpha * ag__.converted_call(tf.nn.elu, (z,), None, fscope)), None, fscope))\n",
       "  do_return,\n",
       "  return ag__.retval(retval_)\n",
       "\n",
       "'''"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(scaled_elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConversionError",
     "evalue": "converting <tensorflow.python.eager.def_function.Function object at 0x0000000015FC4978>: ValueError: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mG:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mto_graph\u001b[1;34m(entity, recursive, experimental_optional_features)\u001b[0m\n\u001b[0;32m    641\u001b[0m         autograph_module=tf_inspect.getmodule(to_graph))\n\u001b[1;32m--> 642\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogram_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNameError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\conversion.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(entity, program_ctx)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__code__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m       raise ValueError('Cannot apply autograph to a function that doesn\\'t '\n\u001b[0m\u001b[0;32m    312\u001b[0m                        \u001b[1;34m'expose a __code__ object. If this is a @tf.function,'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConversionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4078a84ea4c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_tf_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverge_to_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-e119927b4cbb>\u001b[0m in \u001b[0;36mdisplay_tf_code\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#使用tf中的autograph 将python 函数转化为 tf函数 展示\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_tf_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'''python\\n{}\\n'''\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mto_code\u001b[1;34m(entity, recursive, experimental_optional_features)\u001b[0m\n\u001b[0;32m    813\u001b[0m           \u001b[0mentity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m           \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m           experimental_optional_features=experimental_optional_features))\n\u001b[0m\u001b[0;32m    816\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtextwrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdedent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mto_graph\u001b[1;34m(entity, recursive, experimental_optional_features)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Error converting %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     raise ConversionError('converting {}: {}: {}'.format(\n\u001b[1;32m--> 646\u001b[1;33m         entity, e.__class__.__name__, str(e)))\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConversionError\u001b[0m: converting <tensorflow.python.eager.def_function.Function object at 0x0000000015FC4978>: ValueError: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead."
     ]
    }
   ],
   "source": [
    "display_tf_code(converge_to_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#变量创建需要放在函数外面\n",
    "var = tf.Variable(0.)\n",
    "@tf.function\n",
    "def add_21():\n",
    "    return var.assign_add(21)\n",
    "print(add_21())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None,), dtype=tf.int32, name='x'))\n",
      "tf.Tensor([ 1  8 27], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#函数签名，限定参数类型\n",
    "@tf.function(input_signature=[tf.TensorSpec([None],tf.int32,name='x')])\n",
    "def cube(z):\n",
    "    return tf.pow(z,3)\n",
    "try:\n",
    "    print(cube(tf.constant([1.,2.,3.])))\n",
    "except ValueError as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(cube(tf.constant([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.eager.function.ConcreteFunction object at 0x0000000016324160>\n"
     ]
    }
   ],
   "source": [
    "# @tf.function 将 py func -> tf graph\n",
    "# 可以使用get_concrete_function 通过 add input singnature 便于 SaveModel\n",
    "cube_func_int32 = cube.get_concrete_function(tf.TensorSpec([None],tf.int32))\n",
    "print(cube_func_int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(cube_func_int32 is cube.get_concrete_function(tf.TensorSpec([5],tf.int32)))\n",
    "print(cube_func_int32 is cube.get_concrete_function(tf.constant([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x162f14e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Pow/y' type=Const>,\n",
       " <tf.Operation 'Pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Pow\"\n",
      "op: \"Pow\"\n",
      "input: \"x\"\n",
      "input: \"Pow/y\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pow_op = cube_func_int32.graph.get_operations()[2]\n",
    "print(pow_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'x:0' shape=(None,) dtype=int32>, <tf.Tensor 'Pow/y:0' shape=() dtype=int32>]\n",
      "[<tf.Tensor 'Pow:0' shape=(None,) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "print(list(pow_op.inputs))\n",
    "print(list(pow_op.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"x\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"_user_specified_name\"\n",
       "    value {\n",
       "      s: \"x\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Pow/y\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Pow\"\n",
       "  op: \"Pow\"\n",
       "  input: \"x\"\n",
       "  input: \"Pow/y\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity\"\n",
       "  op: \"Identity\"\n",
       "  input: \"Pow\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 175\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph.get_operation_by_name(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'x:0' shape=(None,) dtype=int32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph.get_tensor_by_name(\"x:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.999999999999119\n"
     ]
    }
   ],
   "source": [
    "#自定义求导\n",
    "def f(x):\n",
    "    return 3.* x ** 2 + 2 * x - 1\n",
    "\n",
    "def approximae_derivative(f,x,eps = 1e-3):\n",
    "    return (f(x+eps) - f(x-eps)) / (2*eps)\n",
    "print(approximae_derivative(f,1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8.999999999993236, 41.999999999994486)\n"
     ]
    }
   ],
   "source": [
    "#多元求导\n",
    "def g(x1,x2):\n",
    "    return (x1+5)*(x2**2)\n",
    "def approximate_gradient(g,x1,x2,eps=1e-3):\n",
    "    #对x1求偏导\n",
    "    dg_x1 = approximae_derivative(lambda x: g(x,x2),x1,eps)\n",
    "    #对x2求偏导\n",
    "    dg_x2 = approximae_derivative(lambda x: g(x1,x),x2,eps)\n",
    "    return dg_x1,dg_x2\n",
    "\n",
    "print(approximate_gradient(g,2.,3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "GradientTape.gradient can only be called once on non-persistent tapes.\n"
     ]
    }
   ],
   "source": [
    "#使用tf api 求导\n",
    "x1 = tf.Variable(2.0)\n",
    "x2 = tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = g(x1,x2)\n",
    "dz_x1 = tape.gradient(z,x1)\n",
    "print(dz_x1)\n",
    "#tf.GradientTape()参数persistent需要设置为True ,否则with上下文使用一次会自动关闭tape\n",
    "try:\n",
    "    dz_x2 = tape.gradient(z,x2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(42.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#使用tf api 求导\n",
    "x1 = tf.Variable(2.0)\n",
    "x2 = tf.Variable(3.0)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = g(x1,x2)\n",
    "dz_x1 = tape.gradient(z,x1)\n",
    "print(dz_x1)\n",
    "#tf.GradientTape()参数persistent需要设置为True ,否则with上下文使用一次会自动关闭tape,并且使用完后需要自己手动del删除关闭\n",
    "try:\n",
    "    dz_x2 = tape.gradient(z,x2)\n",
    "    print(dz_x2)\n",
    "    del tape\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=9.0>, <tf.Tensor: shape=(), dtype=float32, numpy=42.0>]\n"
     ]
    }
   ],
   "source": [
    "#使用tf api 求导，或者我们可以传入求偏导自变量数组，一次求就不必设置persistent为True\n",
    "x1 = tf.Variable(2.0)\n",
    "x2 = tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = g(x1,x2)\n",
    "dz_x1x2 = tape.gradient(z,[x1,x2])\n",
    "print(dz_x1x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=9.0>, <tf.Tensor: shape=(), dtype=float32, numpy=42.0>]\n"
     ]
    }
   ],
   "source": [
    "#使用tf api 求导，对于常量，默认无法求导，需要tape.watch来关注常量方可\n",
    "x1 = tf.constant(2.0)\n",
    "x2 = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1,x2])\n",
    "    z = g(x1,x2)\n",
    "dz_x1x2 = tape.gradient(z,[x1,x2])\n",
    "print(dz_x1x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#多个函数对同一变量求导的和\n",
    "x = tf.Variable(5.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = 3 * x \n",
    "    z2 = x ** 2\n",
    "tape.gradient([z1,z2],x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=6.0>, <tf.Tensor: shape=(), dtype=float32, numpy=14.0>]]\n"
     ]
    }
   ],
   "source": [
    "#求解二阶导数\n",
    "#使用tf api 求导，对于常量，默认无法求导，需要tape.watch来关注常量方可\n",
    "x1 = tf.Variable(2.0)\n",
    "x2 = tf.Variable(3.0)\n",
    "def t(x1,x2):\n",
    "    return (x1+5)*(x2**2)\n",
    "with tf.GradientTape(persistent=True) as second_tape:\n",
    "    with tf.GradientTape(persistent=True) as first_tape:\n",
    "        z = t(x1,x2)\n",
    "    first_grads = first_tape.gradient(z,[x1,x2])\n",
    "second_grads = [second_tape.gradient(first_grad,[x1,x2]) for first_grad in first_grads]\n",
    "print(second_grads)\n",
    "\n",
    "del first_tape\n",
    "del second_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.33264837>\n",
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.33333194>\n"
     ]
    }
   ],
   "source": [
    "#模拟带学习率的梯度下降\n",
    "def k(x):\n",
    "    return 3.* x ** 2 + 2. * x - 1.\n",
    "learning_rate = 1e-2\n",
    "x = tf.Variable(0.0)\n",
    "for _ in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z = k(x)\n",
    "    dz_dx = tape.gradient(z,x)\n",
    "    x.assign_sub(learning_rate * dz_dx)\n",
    "print(x)\n",
    "\n",
    "#使用keras 模拟\n",
    "optimizer = tf.keras.optimizers.SGD(lr = learning_rate)\n",
    "for _ in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z = k(x)\n",
    "    dz_dx = tape.gradient(z,x)\n",
    "    optimizer.apply_gradients([(dz_dx,x)])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
